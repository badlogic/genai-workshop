{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMLhJxL7Pl9S/dcl0xWVU8F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e1dcab08cb12469786d864dc1b93e749": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_925cd53c55a24d6287e5d660c03f4fae",
              "IPY_MODEL_06367205bfdf4874a79523698ac319ef",
              "IPY_MODEL_3fc6841d223f4a218b0b45cbe5f1a7cd"
            ],
            "layout": "IPY_MODEL_ad0444a0db1a4ffe808f475fbfa10587"
          }
        },
        "925cd53c55a24d6287e5d660c03f4fae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3a778f8fddd44b186f860a7d736b261",
            "placeholder": "​",
            "style": "IPY_MODEL_ec740499a4c94fb3a6b34612391b11a4",
            "value": "Downloading readme: 100%"
          }
        },
        "06367205bfdf4874a79523698ac319ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9afaef051c08431a9a912796029a3fc5",
            "max": 10464,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_36646847c9124289a7c1f7ff09630212",
            "value": 10464
          }
        },
        "3fc6841d223f4a218b0b45cbe5f1a7cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1221c5d4f0d49ffaca08270f46b1dfd",
            "placeholder": "​",
            "style": "IPY_MODEL_cf5656f93c5143fea45bebb1628bed7a",
            "value": " 10.5k/10.5k [00:00&lt;00:00, 463kB/s]"
          }
        },
        "ad0444a0db1a4ffe808f475fbfa10587": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3a778f8fddd44b186f860a7d736b261": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec740499a4c94fb3a6b34612391b11a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9afaef051c08431a9a912796029a3fc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36646847c9124289a7c1f7ff09630212": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b1221c5d4f0d49ffaca08270f46b1dfd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf5656f93c5143fea45bebb1628bed7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4bfd413fcd3044adb964227c42e3452e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_113b00bc74844b32a847cc447b4b94f6",
              "IPY_MODEL_195c6f216bb840f6812a3b528834cf64",
              "IPY_MODEL_eefdf0ccd14d46399e3d4ac4ce176bd6"
            ],
            "layout": "IPY_MODEL_f40e921d62a043a2a9f3663a2799cff5"
          }
        },
        "113b00bc74844b32a847cc447b4b94f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a263da8f90be43c2b57e63648b01596c",
            "placeholder": "​",
            "style": "IPY_MODEL_9ba8cd88135e430fbafc126c908fb926",
            "value": "Downloading data: 100%"
          }
        },
        "195c6f216bb840f6812a3b528834cf64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8e70c8fa8af4430897935decf720293",
            "max": 732610,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8014e067d69e48eaafc029752f123e4c",
            "value": 732610
          }
        },
        "eefdf0ccd14d46399e3d4ac4ce176bd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_414d105d12bb4d02a21f2db984713017",
            "placeholder": "​",
            "style": "IPY_MODEL_2d4e44dcb35e48a48b7302a6d2102a41",
            "value": " 733k/733k [00:00&lt;00:00, 3.34MB/s]"
          }
        },
        "f40e921d62a043a2a9f3663a2799cff5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a263da8f90be43c2b57e63648b01596c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ba8cd88135e430fbafc126c908fb926": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c8e70c8fa8af4430897935decf720293": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8014e067d69e48eaafc029752f123e4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "414d105d12bb4d02a21f2db984713017": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d4e44dcb35e48a48b7302a6d2102a41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc87b50718c84e2aa0631ace37aaf63a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e671b33a83ee42c8bd0eaa9b7e662b98",
              "IPY_MODEL_29d995eff6874ae4a83e13339b2b8907",
              "IPY_MODEL_1f14e1b738a1426f9712121ae789b1e8"
            ],
            "layout": "IPY_MODEL_733d5df6541049bf9a84a119f9cfe8d8"
          }
        },
        "e671b33a83ee42c8bd0eaa9b7e662b98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe204fcc4bcd4b7a9a7eeb1c4f874e94",
            "placeholder": "​",
            "style": "IPY_MODEL_bead20f7146241a1aa05e4593a3aad05",
            "value": "Downloading data: 100%"
          }
        },
        "29d995eff6874ae4a83e13339b2b8907": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ced4f128c5264386be43acb694dfac51",
            "max": 6357543,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9f5d860689934b2eb4728a92d5f2d107",
            "value": 6357543
          }
        },
        "1f14e1b738a1426f9712121ae789b1e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29c627e8beed4fd0b4d47de4a082b1b0",
            "placeholder": "​",
            "style": "IPY_MODEL_de56c667ee81450e98fd71c453a13b80",
            "value": " 6.36M/6.36M [00:00&lt;00:00, 20.0MB/s]"
          }
        },
        "733d5df6541049bf9a84a119f9cfe8d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe204fcc4bcd4b7a9a7eeb1c4f874e94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bead20f7146241a1aa05e4593a3aad05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ced4f128c5264386be43acb694dfac51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f5d860689934b2eb4728a92d5f2d107": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "29c627e8beed4fd0b4d47de4a082b1b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de56c667ee81450e98fd71c453a13b80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "484170c735194f2eb57177a11f729566": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0ad4c906b0ae49d288b9446a3d85ac90",
              "IPY_MODEL_9af680e021a04f13a1de5720f66e6ea2",
              "IPY_MODEL_94ef81e619f94d219a5510c3905d7c76"
            ],
            "layout": "IPY_MODEL_08f4340859684942917056546f88f112"
          }
        },
        "0ad4c906b0ae49d288b9446a3d85ac90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fada48e1d7af43c5a9558b6cac50ce35",
            "placeholder": "​",
            "style": "IPY_MODEL_84f396c2c2584214b2472c9bf6a2e438",
            "value": "Downloading data: 100%"
          }
        },
        "9af680e021a04f13a1de5720f66e6ea2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1845c9bec669424fb25e09e74476d1b2",
            "max": 657209,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_15539dffe45b447baf64c6039638abc6",
            "value": 657209
          }
        },
        "94ef81e619f94d219a5510c3905d7c76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4021b5da25545b4a06fc1ec21e478f5",
            "placeholder": "​",
            "style": "IPY_MODEL_164ccde2c0814930b949a0f62decfb51",
            "value": " 657k/657k [00:00&lt;00:00, 3.75MB/s]"
          }
        },
        "08f4340859684942917056546f88f112": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fada48e1d7af43c5a9558b6cac50ce35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84f396c2c2584214b2472c9bf6a2e438": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1845c9bec669424fb25e09e74476d1b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15539dffe45b447baf64c6039638abc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d4021b5da25545b4a06fc1ec21e478f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "164ccde2c0814930b949a0f62decfb51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "460e5e2396b94d1da3bc0240a782ecb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1a1e8e6a0cd74a91b97f47fb0a1f9ccb",
              "IPY_MODEL_17db74bf221045819306ad3a02302bb9",
              "IPY_MODEL_454fe269788c4c46a79fce888a2038f3"
            ],
            "layout": "IPY_MODEL_4410748dabf14d98bdbf7701088d05ff"
          }
        },
        "1a1e8e6a0cd74a91b97f47fb0a1f9ccb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d32a25d235846178bfbb2a11fd9df35",
            "placeholder": "​",
            "style": "IPY_MODEL_c8424ac7a0af4736a36d4b64449e4c3b",
            "value": "Generating test split: 100%"
          }
        },
        "17db74bf221045819306ad3a02302bb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_391c3a8a2b9e48528e490b9ff18c603b",
            "max": 4358,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_13241a6174e34a17a4cd958712b4367b",
            "value": 4358
          }
        },
        "454fe269788c4c46a79fce888a2038f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3d5286aa02c4e3b9af7f2a020521ea3",
            "placeholder": "​",
            "style": "IPY_MODEL_35207e0877934f42aa8d61ab1bf5e34c",
            "value": " 4358/4358 [00:00&lt;00:00, 39393.07 examples/s]"
          }
        },
        "4410748dabf14d98bdbf7701088d05ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d32a25d235846178bfbb2a11fd9df35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8424ac7a0af4736a36d4b64449e4c3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "391c3a8a2b9e48528e490b9ff18c603b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13241a6174e34a17a4cd958712b4367b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c3d5286aa02c4e3b9af7f2a020521ea3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35207e0877934f42aa8d61ab1bf5e34c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "47da5e40e355464280e6350d838d285e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_593abd6d71f64ee49631517fbcf4e33d",
              "IPY_MODEL_a4bdcb29da7f4e1f90413d5266a895e4",
              "IPY_MODEL_e3b4b28b21a74a13ab2d5862e83ffdd1"
            ],
            "layout": "IPY_MODEL_930cbc5a79354fc8b83489da889f9d0d"
          }
        },
        "593abd6d71f64ee49631517fbcf4e33d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5930532da2d4033b3b8a89d6e0b1d42",
            "placeholder": "​",
            "style": "IPY_MODEL_5c58657e7cd24765bb3a6d61ae36bdb8",
            "value": "Generating train split: 100%"
          }
        },
        "a4bdcb29da7f4e1f90413d5266a895e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a149750e3c6e46088808c1dc313698de",
            "max": 36718,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7488e777ef07487b9d4c8f555a084abe",
            "value": 36718
          }
        },
        "e3b4b28b21a74a13ab2d5862e83ffdd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_703caa0f143f4e97a5c51ad42407a468",
            "placeholder": "​",
            "style": "IPY_MODEL_2843580b82754f7bb57f0ace7012ebbb",
            "value": " 36718/36718 [00:00&lt;00:00, 249130.56 examples/s]"
          }
        },
        "930cbc5a79354fc8b83489da889f9d0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5930532da2d4033b3b8a89d6e0b1d42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c58657e7cd24765bb3a6d61ae36bdb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a149750e3c6e46088808c1dc313698de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7488e777ef07487b9d4c8f555a084abe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "703caa0f143f4e97a5c51ad42407a468": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2843580b82754f7bb57f0ace7012ebbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d56879031504d7d96e260e676b633a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_754fc96a95614d33941f8c4bc550a778",
              "IPY_MODEL_291d90cee6be4235bac7707ccf25cecd",
              "IPY_MODEL_5a4f9b3661174330aa664be09efb9a61"
            ],
            "layout": "IPY_MODEL_aee76cda85b74c0fbcf164486608c78b"
          }
        },
        "754fc96a95614d33941f8c4bc550a778": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53434a2815c642709dd72d7b51d4234f",
            "placeholder": "​",
            "style": "IPY_MODEL_f35768538818488a92d4a50344e48ff7",
            "value": "Generating validation split: 100%"
          }
        },
        "291d90cee6be4235bac7707ccf25cecd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f84c83df6ee147c3ab4da7a2d74b50d6",
            "max": 3760,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_715ae121b2c841668598d256537ece13",
            "value": 3760
          }
        },
        "5a4f9b3661174330aa664be09efb9a61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_857f28ffea1647d085c778be935258b8",
            "placeholder": "​",
            "style": "IPY_MODEL_13fb9054d018490797b5bc9271853d62",
            "value": " 3760/3760 [00:00&lt;00:00, 67050.94 examples/s]"
          }
        },
        "aee76cda85b74c0fbcf164486608c78b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53434a2815c642709dd72d7b51d4234f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f35768538818488a92d4a50344e48ff7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f84c83df6ee147c3ab4da7a2d74b50d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "715ae121b2c841668598d256537ece13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "857f28ffea1647d085c778be935258b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13fb9054d018490797b5bc9271853d62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/badlogic/genai-workshop/blob/main/04_unsupervised_learning_language_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Language Models\n",
        "Language models are at the core of the recent AI hype, brought to you by OpenAI's ChatGPT, products like GitHub's Copilot, or open-source models like Llama.\n",
        "\n",
        "As described in [the unsupervised learning overview](https://colab.research.google.com/drive/10tlC17BRVoX9aPp66orqiI16iUzLx-4p?usp=sharing), the goal of language models is it to predict the likelihood of a sequence of **tokens** in a language. A token can be a word or punctuation in the simplest case. There are more sophisticated tokenizers that break words down into sub-units, like [binary pair encoding](https://en.wikipedia.org/wiki/Byte_pair_encoding) or [SentencePiece](https://github.com/google/sentencepiece).\n",
        "\n",
        "A language model learns patterns and structures based on large amounts of text data to generate or understand text. The patterns are learned in an unsupervised manner directly from the training data.\n",
        "\n",
        "Such models can then be used to predict the next token in a sequence, or fill in a token in-between other tokens of a text.\n",
        "\n",
        "Let's create a simple language model of our own, to build an initial intution about such models, before we dive into the current state-of-the-art in more depth."
      ],
      "metadata": {
        "id": "3SPT9uhDv-D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A naive n-gram language model\n",
        "The simplest language model we can build is an [n-gram model](https://en.wikipedia.org/wiki/Word_n-gram_language_model), based on word tokens.\n"
      ],
      "metadata": {
        "id": "YtIVoNLUyVnf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation\n",
        "Before we start building the model, we need some data to learn from. We'll use a small [Wikipedia dataset](https://huggingface.co/datasets/wikitext/viewer/wikitext-2-raw-v1), consisting of about ~44k paragraphs from Wikipedia articles, of which we use ~36k to train the language model (\"train\" split)."
      ],
      "metadata": {
        "id": "XQ6E62TF60L6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBulGBoMBaRn",
        "outputId": "b77302a9-44aa-43dc-e5e3-380dc4be91e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "\n",
        "paragraphs = load_dataset('wikitext', 'wikitext-2-raw-v1')[\"train\"];\n",
        "print(f'{len(paragraphs)} paragraphs')\n",
        "pd.DataFrame(paragraphs[\"text\"][:100], columns=[\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666,
          "referenced_widgets": [
            "e1dcab08cb12469786d864dc1b93e749",
            "925cd53c55a24d6287e5d660c03f4fae",
            "06367205bfdf4874a79523698ac319ef",
            "3fc6841d223f4a218b0b45cbe5f1a7cd",
            "ad0444a0db1a4ffe808f475fbfa10587",
            "b3a778f8fddd44b186f860a7d736b261",
            "ec740499a4c94fb3a6b34612391b11a4",
            "9afaef051c08431a9a912796029a3fc5",
            "36646847c9124289a7c1f7ff09630212",
            "b1221c5d4f0d49ffaca08270f46b1dfd",
            "cf5656f93c5143fea45bebb1628bed7a",
            "4bfd413fcd3044adb964227c42e3452e",
            "113b00bc74844b32a847cc447b4b94f6",
            "195c6f216bb840f6812a3b528834cf64",
            "eefdf0ccd14d46399e3d4ac4ce176bd6",
            "f40e921d62a043a2a9f3663a2799cff5",
            "a263da8f90be43c2b57e63648b01596c",
            "9ba8cd88135e430fbafc126c908fb926",
            "c8e70c8fa8af4430897935decf720293",
            "8014e067d69e48eaafc029752f123e4c",
            "414d105d12bb4d02a21f2db984713017",
            "2d4e44dcb35e48a48b7302a6d2102a41",
            "cc87b50718c84e2aa0631ace37aaf63a",
            "e671b33a83ee42c8bd0eaa9b7e662b98",
            "29d995eff6874ae4a83e13339b2b8907",
            "1f14e1b738a1426f9712121ae789b1e8",
            "733d5df6541049bf9a84a119f9cfe8d8",
            "fe204fcc4bcd4b7a9a7eeb1c4f874e94",
            "bead20f7146241a1aa05e4593a3aad05",
            "ced4f128c5264386be43acb694dfac51",
            "9f5d860689934b2eb4728a92d5f2d107",
            "29c627e8beed4fd0b4d47de4a082b1b0",
            "de56c667ee81450e98fd71c453a13b80",
            "484170c735194f2eb57177a11f729566",
            "0ad4c906b0ae49d288b9446a3d85ac90",
            "9af680e021a04f13a1de5720f66e6ea2",
            "94ef81e619f94d219a5510c3905d7c76",
            "08f4340859684942917056546f88f112",
            "fada48e1d7af43c5a9558b6cac50ce35",
            "84f396c2c2584214b2472c9bf6a2e438",
            "1845c9bec669424fb25e09e74476d1b2",
            "15539dffe45b447baf64c6039638abc6",
            "d4021b5da25545b4a06fc1ec21e478f5",
            "164ccde2c0814930b949a0f62decfb51",
            "460e5e2396b94d1da3bc0240a782ecb2",
            "1a1e8e6a0cd74a91b97f47fb0a1f9ccb",
            "17db74bf221045819306ad3a02302bb9",
            "454fe269788c4c46a79fce888a2038f3",
            "4410748dabf14d98bdbf7701088d05ff",
            "7d32a25d235846178bfbb2a11fd9df35",
            "c8424ac7a0af4736a36d4b64449e4c3b",
            "391c3a8a2b9e48528e490b9ff18c603b",
            "13241a6174e34a17a4cd958712b4367b",
            "c3d5286aa02c4e3b9af7f2a020521ea3",
            "35207e0877934f42aa8d61ab1bf5e34c",
            "47da5e40e355464280e6350d838d285e",
            "593abd6d71f64ee49631517fbcf4e33d",
            "a4bdcb29da7f4e1f90413d5266a895e4",
            "e3b4b28b21a74a13ab2d5862e83ffdd1",
            "930cbc5a79354fc8b83489da889f9d0d",
            "d5930532da2d4033b3b8a89d6e0b1d42",
            "5c58657e7cd24765bb3a6d61ae36bdb8",
            "a149750e3c6e46088808c1dc313698de",
            "7488e777ef07487b9d4c8f555a084abe",
            "703caa0f143f4e97a5c51ad42407a468",
            "2843580b82754f7bb57f0ace7012ebbb",
            "4d56879031504d7d96e260e676b633a9",
            "754fc96a95614d33941f8c4bc550a778",
            "291d90cee6be4235bac7707ccf25cecd",
            "5a4f9b3661174330aa664be09efb9a61",
            "aee76cda85b74c0fbcf164486608c78b",
            "53434a2815c642709dd72d7b51d4234f",
            "f35768538818488a92d4a50344e48ff7",
            "f84c83df6ee147c3ab4da7a2d74b50d6",
            "715ae121b2c841668598d256537ece13",
            "857f28ffea1647d085c778be935258b8",
            "13fb9054d018490797b5bc9271853d62"
          ]
        },
        "id": "kPaA8qvZBY07",
        "outputId": "b87f7bbf-d43e-4546-9862-8ff6a8c8383e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e1dcab08cb12469786d864dc1b93e749"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/733k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4bfd413fcd3044adb964227c42e3452e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/6.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cc87b50718c84e2aa0631ace37aaf63a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/657k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "484170c735194f2eb57177a11f729566"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/4358 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "460e5e2396b94d1da3bc0240a782ecb2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/36718 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "47da5e40e355464280e6350d838d285e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/3760 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4d56879031504d7d96e260e676b633a9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36718 paragraphs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 text\n",
              "0                                                    \n",
              "1                      = Valkyria Chronicles III = \\n\n",
              "2                                                    \n",
              "3    Senjō no Valkyria 3 : Unrecorded Chronicles (...\n",
              "4    The game began development in 2010 , carrying...\n",
              "..                                                ...\n",
              "95   75 @,@ 000 buck & ball cartridges - percussio...\n",
              "96       14 @,@ 000 buck & ball cartridges - flint \\n\n",
              "97                                 275 paper fuzes \\n\n",
              "98        117 rounds , 6 @-@ pounder canister shot \\n\n",
              "99            130 rounds , 6 @-@ pounder ball shot \\n\n",
              "\n",
              "[100 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-30848ba0-d4a8-4c02-b2b1-fdcaa64d8627\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>= Valkyria Chronicles III = \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Senjō no Valkyria 3 : Unrecorded Chronicles (...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The game began development in 2010 , carrying...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>75 @,@ 000 buck &amp; ball cartridges - percussio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>14 @,@ 000 buck &amp; ball cartridges - flint \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>275 paper fuzes \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>117 rounds , 6 @-@ pounder canister shot \\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>130 rounds , 6 @-@ pounder ball shot \\n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 1 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-30848ba0-d4a8-4c02-b2b1-fdcaa64d8627')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-30848ba0-d4a8-4c02-b2b1-fdcaa64d8627 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-30848ba0-d4a8-4c02-b2b1-fdcaa64d8627');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-dfd72a48-b2d3-42e9-b6ca-20add19a052a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dfd72a48-b2d3-42e9-b6ca-20add19a052a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-dfd72a48-b2d3-42e9-b6ca-20add19a052a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 76,\n        \"samples\": [\n          \" It met with positive sales in Japan , and was praised by both Japanese and western critics . After release , it received downloadable content , along with an expanded edition in November of that year . It was also adapted into manga and an original video animation series . Due to low sales of Valkyria Chronicles II , Valkyria Chronicles III was not localized , but a fan translation compatible with the game 's expanded edition was released in 2014 . Media.Vision would return to the franchise with the development of Valkyria : Azure Revolution for the PlayStation 4 . \\n\",\n          \" = = Construction = = \\n\",\n          \" The game takes place during the Second Europan War . Gallian Army Squad 422 , also known as \\\" The Nameless \\\" , are a penal military unit composed of criminals , foreign deserters , and military offenders whose real names are erased from the records and thereon officially referred to by numbers . Ordered by the Gallian military to perform the most dangerous missions that the Regular Army and Militia will not do , they are nevertheless up to the task , exemplified by their motto , Altaha Abilia , meaning \\\" Always Ready . \\\" The three main characters are No.7 Kurt Irving , an army officer falsely accused of treason who wishes to redeem himself ; Ace No.1 Imca , a female Darcsen heavy weapons specialist who seeks revenge against the Valkyria who destroyed her home ; and No.13 Riela Marcellis , a seemingly jinxed young woman who is unknowingly a descendant of the Valkyria . Together with their fellow squad members , these three are tasked to fight against a mysterious Imperial unit known as Calamity Raven , consisting of mostly Darcsen soldiers . \\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we need to split each paragraph into sentences, and each sentence into word tokens. We use the sentence splitter and tokenizer from [NLTK](https://www.nltk.org/) to achieve this."
      ],
      "metadata": {
        "id": "kBDoHakF6-h-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "sentences = [word_tokenize(sentence) for text in paragraphs['text'] for sentence in sent_tokenize(text)]"
      ],
      "metadata": {
        "id": "tZDYpsv6DRLi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "877b3a99-8890-41b7-b8df-ac66d7992e5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's one tokenized sentence."
      ],
      "metadata": {
        "id": "SAevoDdBu24t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(sentences[10], columns=[\"token\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        },
        "id": "Ct9l-zvk7xBP",
        "outputId": "659ef424-4237-4f4e-840c-7575c09c204f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       token\n",
              "0         It\n",
              "1        met\n",
              "2       with\n",
              "3   positive\n",
              "4      sales\n",
              "5         in\n",
              "6      Japan\n",
              "7          ,\n",
              "8        and\n",
              "9        was\n",
              "10   praised\n",
              "11        by\n",
              "12      both\n",
              "13  Japanese\n",
              "14       and\n",
              "15   western\n",
              "16   critics\n",
              "17         ."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f3015ca5-d4b6-474d-8bea-40a6a1532203\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>token</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>It</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>met</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>with</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sales</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>in</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Japan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>and</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>was</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>praised</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>by</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Japanese</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>and</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>western</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>critics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f3015ca5-d4b6-474d-8bea-40a6a1532203')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f3015ca5-d4b6-474d-8bea-40a6a1532203 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f3015ca5-d4b6-474d-8bea-40a6a1532203');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-12218ab1-8cd1-476c-9e23-14c1274970af\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-12218ab1-8cd1-476c-9e23-14c1274970af')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-12218ab1-8cd1-476c-9e23-14c1274970af button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 18,\n  \"fields\": [\n    {\n      \"column\": \"token\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 17,\n        \"samples\": [\n          \"It\",\n          \"met\",\n          \"in\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training\n",
        "\n",
        "Time to train the language model. The algorithm may look a bit daunting, but the concept is very simply.\n",
        "\n",
        "We first check that the provided parameter `n` is valid, that is, is bigger or equal to 1.\n",
        "\n",
        "Next we instantiate a dictionary called `n_gram_stats`, which maps from a prefix to a dictionary. The dictionary for a prefix contains all the tokens and their counts that were observed in the training data following the prefix.\n",
        "\n",
        "Next, we iterate through all sentences. For each sentence, we iterate through all token positions.\n",
        "\n",
        "For each token position, we initialize the prefix to the empty string. We then iterate through all token positions from the current token position to the current token position + `n`. In each step, we get the current token for the position and add one to the dictionary entry of its prefix. We then expand the prefix with this token, and move on to the next token position.\n",
        "\n",
        "Once we've collected all statistics, we convert each dictionary for a prefix to a list, and sort the `(token, count)` tuples in descending order by count. This will later help us speed up generation.\n",
        "\n",
        "> **Note:** standard n-gram models are probabilistic in nature and would normalize the counts to model probability distributions. For our purposes, it's sufficient to stick to the raw counts.\n",
        "\n",
        "Execute the code below to see the training algorithm build a model over the single sentence `\"The quick brown fox jumped over the lazy dog\"` using `n=5`. The debug parameter is set to `True`, so the training code will output all n-grams it records counts for."
      ],
      "metadata": {
        "id": "PcPzjOKp8c26"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "def train_lm(sentences, n, debug=False):\n",
        "  if (n < 1):\n",
        "    raise ValueError(\"n must be >= 1\")\n",
        "  n_gram_stats = defaultdict(lambda: defaultdict(int))\n",
        "  for sentence in sentences:\n",
        "    for i in range(len(sentence)):\n",
        "      prefix = \"\"\n",
        "      for j in range(0, n):\n",
        "        if i + j < len(sentence):\n",
        "          token = sentence[i + j]\n",
        "          n_gram_stats[prefix][token] += 1\n",
        "          if (debug):\n",
        "            print(f'{prefix} -> {token}')\n",
        "          prefix += (\" \" if prefix else \"\") + token\n",
        "\n",
        "  for prefix, token_counts in n_gram_stats.items():\n",
        "    sorted_token_counts = sorted(token_counts.items(), key=lambda item: item[1], reverse=True)\n",
        "    n_gram_stats[prefix] = sorted_token_counts\n",
        "\n",
        "  return n_gram_stats\n",
        "\n",
        "sentence = [\"The\", \"quick\", \"quick\", \"brown\", \"fox\", \"jumped\", \"over\", \"the\", \"lazy\", \"dog\", \".\"];\n",
        "model = train_lm([sentence], 5, True)"
      ],
      "metadata": {
        "id": "yjFz5FZkMd2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7f3f4af-3307-4964-a623-28fe12d59fd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " -> The\n",
            "The -> quick\n",
            "The quick -> quick\n",
            "The quick quick -> brown\n",
            "The quick quick brown -> fox\n",
            " -> quick\n",
            "quick -> quick\n",
            "quick quick -> brown\n",
            "quick quick brown -> fox\n",
            "quick quick brown fox -> jumped\n",
            " -> quick\n",
            "quick -> brown\n",
            "quick brown -> fox\n",
            "quick brown fox -> jumped\n",
            "quick brown fox jumped -> over\n",
            " -> brown\n",
            "brown -> fox\n",
            "brown fox -> jumped\n",
            "brown fox jumped -> over\n",
            "brown fox jumped over -> the\n",
            " -> fox\n",
            "fox -> jumped\n",
            "fox jumped -> over\n",
            "fox jumped over -> the\n",
            "fox jumped over the -> lazy\n",
            " -> jumped\n",
            "jumped -> over\n",
            "jumped over -> the\n",
            "jumped over the -> lazy\n",
            "jumped over the lazy -> dog\n",
            " -> over\n",
            "over -> the\n",
            "over the -> lazy\n",
            "over the lazy -> dog\n",
            "over the lazy dog -> .\n",
            " -> the\n",
            "the -> lazy\n",
            "the lazy -> dog\n",
            "the lazy dog -> .\n",
            " -> lazy\n",
            "lazy -> dog\n",
            "lazy dog -> .\n",
            " -> dog\n",
            "dog -> .\n",
            " -> .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also output the recorded counts for each `prefix -> token` pair the model learned."
      ],
      "metadata": {
        "id": "5rKjdXL5IUnu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for prefix, tokens in model.items():\n",
        "  for token, count in tokens:\n",
        "    print(f'\"{prefix}\", \"{token}\" -> {count}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VOkscr7IZtz",
        "outputId": "63d2091c-9eeb-45d2-fc71-289f120fcf3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"\", \"quick\" -> 2\n",
            "\"\", \"The\" -> 1\n",
            "\"\", \"brown\" -> 1\n",
            "\"\", \"fox\" -> 1\n",
            "\"\", \"jumped\" -> 1\n",
            "\"\", \"over\" -> 1\n",
            "\"\", \"the\" -> 1\n",
            "\"\", \"lazy\" -> 1\n",
            "\"\", \"dog\" -> 1\n",
            "\"\", \".\" -> 1\n",
            "\"The\", \"quick\" -> 1\n",
            "\"The quick\", \"quick\" -> 1\n",
            "\"The quick quick\", \"brown\" -> 1\n",
            "\"The quick quick brown\", \"fox\" -> 1\n",
            "\"quick\", \"quick\" -> 1\n",
            "\"quick\", \"brown\" -> 1\n",
            "\"quick quick\", \"brown\" -> 1\n",
            "\"quick quick brown\", \"fox\" -> 1\n",
            "\"quick quick brown fox\", \"jumped\" -> 1\n",
            "\"quick brown\", \"fox\" -> 1\n",
            "\"quick brown fox\", \"jumped\" -> 1\n",
            "\"quick brown fox jumped\", \"over\" -> 1\n",
            "\"brown\", \"fox\" -> 1\n",
            "\"brown fox\", \"jumped\" -> 1\n",
            "\"brown fox jumped\", \"over\" -> 1\n",
            "\"brown fox jumped over\", \"the\" -> 1\n",
            "\"fox\", \"jumped\" -> 1\n",
            "\"fox jumped\", \"over\" -> 1\n",
            "\"fox jumped over\", \"the\" -> 1\n",
            "\"fox jumped over the\", \"lazy\" -> 1\n",
            "\"jumped\", \"over\" -> 1\n",
            "\"jumped over\", \"the\" -> 1\n",
            "\"jumped over the\", \"lazy\" -> 1\n",
            "\"jumped over the lazy\", \"dog\" -> 1\n",
            "\"over\", \"the\" -> 1\n",
            "\"over the\", \"lazy\" -> 1\n",
            "\"over the lazy\", \"dog\" -> 1\n",
            "\"over the lazy dog\", \".\" -> 1\n",
            "\"the\", \"lazy\" -> 1\n",
            "\"the lazy\", \"dog\" -> 1\n",
            "\"the lazy dog\", \".\" -> 1\n",
            "\"lazy\", \"dog\" -> 1\n",
            "\"lazy dog\", \".\" -> 1\n",
            "\"dog\", \".\" -> 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With `n=5`, we learn the counts of sequences with up to `n` tokens. The model can not learn the counts of longer sequences. We can increase `n`, but will eventually run out of memory.\n",
        "\n",
        "Let's build the model over all sentences from our Wikipedia training set using a token window size of `n=8`. We also want to measure the approximate RAM consumption of the resulting model, as well as the execution time of the training."
      ],
      "metadata": {
        "id": "GTROhOxyGIYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import psutil\n",
        "import os\n",
        "import gc\n",
        "import time\n",
        "\n",
        "# Function to get current RAM usage in MB\n",
        "def get_ram_usage():\n",
        "    process = psutil.Process(os.getpid())\n",
        "    return f\"{process.memory_info().rss / 1024 / 1024: .2f} MB\"\n",
        "\n",
        "for i in range(20):\n",
        "  gc.collect()\n",
        "print(f'Before: {get_ram_usage()}')\n",
        "start_time = time.time()\n",
        "\n",
        "model = train_lm(sentences, 8)\n",
        "\n",
        "print(f'After: {get_ram_usage()}')\n",
        "print(f'Took: {time.time() - start_time} seconds')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1WTQS6Y-dSP",
        "outputId": "ba72b75b-cded-451c-92dd-b42d244d2403"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before:  3051.70 MB\n",
            "After:  6540.23 MB\n",
            "Took: 45.75995683670044 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Execution takes around 30-60 seconds, while the model approximately takes up ~3.2GB of RAM. That's a lot for such a small dataset and token window size!\n",
        "\n",
        "We could improve both execution time and RAM usage by employing a smarter encoding scheme. For the sake or brevity, that is left as an exercise to the reader. We should appreciate better what large language models are capable of though. For only 2 to 4 time that amount of (V)RAM, we can run an infinitely more capable large language model like [Llama 7B](https://huggingface.co/meta-llama/Llama-2-7b)."
      ],
      "metadata": {
        "id": "WpG00d15Lw14"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating sentences\n",
        "Given a token sequence, we can now predict the next most likely token using our language model. Let's write a function called `predict_lm` that does just that.\n",
        "\n",
        "It takes as input the model, the sequence for which we want to predict the next token, and two optional parameters `top_k`, which defines how many of he most probable tokens to pick, and `randomize`, which defines if a token should be picked at random from the `top_k` candidate tokens, or if the most probable token should be picked. These two optional parameters define how \"creative\" our language model is allowed to get.\n",
        "\n",
        "The function first tokenizes the input sequence.\n",
        "\n",
        "It then tries to find the longest prefix from the end of the sequence in the model for which a token list is available.\n",
        "\n",
        "If no token list can be found, it fetches the token list for the prefix `\"\"`, which is the list of unigram counts.\n",
        "\n",
        "Next, it selects the top-k tokens from the list based on their count.\n",
        "\n",
        "If randomization is enabled, it will pick a token at random from this list. Otherwise, it will pick the token with the highest count."
      ],
      "metadata": {
        "id": "iyJUSCNaOM3q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def predict_lm(model, sequence, top_k=5, randomize=True, debug=False):\n",
        "    input_tokens = word_tokenize(sequence)\n",
        "    n = max(1, len(input_tokens))\n",
        "    token_list = None\n",
        "\n",
        "    while n > 0 and token_list is None:\n",
        "        prefix = \" \".join(input_tokens[-n:])\n",
        "        if debug:\n",
        "          print(f'Probing prefix \"{prefix}\"')\n",
        "        token_list = model.get(prefix)\n",
        "        if token_list is None:\n",
        "          n -= 1\n",
        "        else:\n",
        "          if debug:\n",
        "            print(f'Full token list for for prefix \"{prefix}\": {token_list}')\n",
        "\n",
        "    if token_list is None:\n",
        "      token_list = model.get(\"\")\n",
        "\n",
        "    top_k_tokens = token_list[:top_k]\n",
        "    if debug:\n",
        "      print(f'Top-k tokens for prefix \"{prefix}\": {top_k_tokens}')\n",
        "    if randomize:\n",
        "        next_token = random.choice(top_k_tokens)[0]\n",
        "    else:\n",
        "        next_token = token_list[0]\n",
        "    return next_token"
      ],
      "metadata": {
        "id": "gIWTI7mvXzTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see what the model predicts for \"The cat in the\""
      ],
      "metadata": {
        "id": "Lfm7qREAW6jy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predict_lm(model, \"The cat in\", 10, True, True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "VU_K7l91W5Ug",
        "outputId": "93403c3a-0cb2-4d4d-f514-5409b79746fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probing prefix \"The cat in\"\n",
            "Probing prefix \"cat in\"\n",
            "Full token list for for prefix \"cat in\": [('the', 1), ('every', 1), ('its', 1)]\n",
            "Top-k tokens for prefix \"cat in\": [('the', 1), ('every', 1), ('its', 1)]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'the'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's write a function called `complete` which generates a complete sentence based on an input query.\n",
        "\n",
        "It takes the same inputs as `predict_lm`, plus an additional parameter `max_tokens`, which defines the maximum number of tokens to generate.\n",
        "\n",
        "The function will call `predict_lm` in a loop, until either a \".\" was predicted, or the maximal number of tokens was generated.\n",
        "\n",
        "The generated token is appended to the current sequence. This extended sequence is then fed back into the model prediction function to generate the next token.\n",
        "\n",
        "This is also how large language models work at the core."
      ],
      "metadata": {
        "id": "6h7Zl5d0Yz8o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def complete_lm(model, sequence, max_tokens=40, top_k=5, randomize=True, debug=False):\n",
        "  for i in range(max_tokens):\n",
        "    next = predict_lm(model, sequence, top_k, randomize, debug)\n",
        "    sequence += \" \" + next\n",
        "    if (next == \".\"):\n",
        "      break;\n",
        "\n",
        "  return sequence"
      ],
      "metadata": {
        "id": "9HkA1WIlh9j4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "complete_lm(model, \"The president of\", 40, 5, True, True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ymu8DOR3NI9B",
        "outputId": "faa7e78e-dbc2-4056-ba30-573ac800c5d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probing prefix \"The president of\"\n",
            "Full token list for for prefix \"The president of\": [('the', 3)]\n",
            "Top-k tokens for prefix \"The president of\": [('the', 3)]\n",
            "Probing prefix \"The president of the\"\n",
            "Full token list for for prefix \"The president of the\": [('Supreme', 1), ('Constitutional', 1), ('university', 1)]\n",
            "Top-k tokens for prefix \"The president of the\": [('Supreme', 1), ('Constitutional', 1), ('university', 1)]\n",
            "Probing prefix \"The president of the Supreme\"\n",
            "Full token list for for prefix \"The president of the Supreme\": [('Court', 1)]\n",
            "Top-k tokens for prefix \"The president of the Supreme\": [('Court', 1)]\n",
            "Probing prefix \"The president of the Supreme Court\"\n",
            "Full token list for for prefix \"The president of the Supreme Court\": [('is', 1)]\n",
            "Top-k tokens for prefix \"The president of the Supreme Court\": [('is', 1)]\n",
            "Probing prefix \"The president of the Supreme Court is\"\n",
            "Full token list for for prefix \"The president of the Supreme Court is\": [('elected', 1)]\n",
            "Top-k tokens for prefix \"The president of the Supreme Court is\": [('elected', 1)]\n",
            "Probing prefix \"The president of the Supreme Court is elected\"\n",
            "Probing prefix \"president of the Supreme Court is elected\"\n",
            "Full token list for for prefix \"president of the Supreme Court is elected\": [('for', 1)]\n",
            "Top-k tokens for prefix \"president of the Supreme Court is elected\": [('for', 1)]\n",
            "Probing prefix \"The president of the Supreme Court is elected for\"\n",
            "Probing prefix \"president of the Supreme Court is elected for\"\n",
            "Probing prefix \"of the Supreme Court is elected for\"\n",
            "Full token list for for prefix \"of the Supreme Court is elected for\": [('a', 1)]\n",
            "Top-k tokens for prefix \"of the Supreme Court is elected for\": [('a', 1)]\n",
            "Probing prefix \"The president of the Supreme Court is elected for a\"\n",
            "Probing prefix \"president of the Supreme Court is elected for a\"\n",
            "Probing prefix \"of the Supreme Court is elected for a\"\n",
            "Probing prefix \"the Supreme Court is elected for a\"\n",
            "Full token list for for prefix \"the Supreme Court is elected for a\": [('four', 1)]\n",
            "Top-k tokens for prefix \"the Supreme Court is elected for a\": [('four', 1)]\n",
            "Probing prefix \"The president of the Supreme Court is elected for a four\"\n",
            "Probing prefix \"president of the Supreme Court is elected for a four\"\n",
            "Probing prefix \"of the Supreme Court is elected for a four\"\n",
            "Probing prefix \"the Supreme Court is elected for a four\"\n",
            "Probing prefix \"Supreme Court is elected for a four\"\n",
            "Full token list for for prefix \"Supreme Court is elected for a four\": [('@', 1)]\n",
            "Top-k tokens for prefix \"Supreme Court is elected for a four\": [('@', 1)]\n",
            "Probing prefix \"The president of the Supreme Court is elected for a four @\"\n",
            "Probing prefix \"president of the Supreme Court is elected for a four @\"\n",
            "Probing prefix \"of the Supreme Court is elected for a four @\"\n",
            "Probing prefix \"the Supreme Court is elected for a four @\"\n",
            "Probing prefix \"Supreme Court is elected for a four @\"\n",
            "Probing prefix \"Court is elected for a four @\"\n",
            "Full token list for for prefix \"Court is elected for a four @\": [('-', 1)]\n",
            "Top-k tokens for prefix \"Court is elected for a four @\": [('-', 1)]\n",
            "Probing prefix \"The president of the Supreme Court is elected for a four @ -\"\n",
            "Probing prefix \"president of the Supreme Court is elected for a four @ -\"\n",
            "Probing prefix \"of the Supreme Court is elected for a four @ -\"\n",
            "Probing prefix \"the Supreme Court is elected for a four @ -\"\n",
            "Probing prefix \"Supreme Court is elected for a four @ -\"\n",
            "Probing prefix \"Court is elected for a four @ -\"\n",
            "Probing prefix \"is elected for a four @ -\"\n",
            "Full token list for for prefix \"is elected for a four @ -\": [('@', 1)]\n",
            "Top-k tokens for prefix \"is elected for a four @ -\": [('@', 1)]\n",
            "Probing prefix \"The president of the Supreme Court is elected for a four @ - @\"\n",
            "Probing prefix \"president of the Supreme Court is elected for a four @ - @\"\n",
            "Probing prefix \"of the Supreme Court is elected for a four @ - @\"\n",
            "Probing prefix \"the Supreme Court is elected for a four @ - @\"\n",
            "Probing prefix \"Supreme Court is elected for a four @ - @\"\n",
            "Probing prefix \"Court is elected for a four @ - @\"\n",
            "Probing prefix \"is elected for a four @ - @\"\n",
            "Probing prefix \"elected for a four @ - @\"\n",
            "Full token list for for prefix \"elected for a four @ - @\": [('year', 1)]\n",
            "Top-k tokens for prefix \"elected for a four @ - @\": [('year', 1)]\n",
            "Probing prefix \"The president of the Supreme Court is elected for a four @ - @ year\"\n",
            "Probing prefix \"president of the Supreme Court is elected for a four @ - @ year\"\n",
            "Probing prefix \"of the Supreme Court is elected for a four @ - @ year\"\n",
            "Probing prefix \"the Supreme Court is elected for a four @ - @ year\"\n",
            "Probing prefix \"Supreme Court is elected for a four @ - @ year\"\n",
            "Probing prefix \"Court is elected for a four @ - @ year\"\n",
            "Probing prefix \"is elected for a four @ - @ year\"\n",
            "Probing prefix \"elected for a four @ - @ year\"\n",
            "Probing prefix \"for a four @ - @ year\"\n",
            "Full token list for for prefix \"for a four @ - @ year\": [('term', 2)]\n",
            "Top-k tokens for prefix \"for a four @ - @ year\": [('term', 2)]\n",
            "Probing prefix \"The president of the Supreme Court is elected for a four @ - @ year term\"\n",
            "Probing prefix \"president of the Supreme Court is elected for a four @ - @ year term\"\n",
            "Probing prefix \"of the Supreme Court is elected for a four @ - @ year term\"\n",
            "Probing prefix \"the Supreme Court is elected for a four @ - @ year term\"\n",
            "Probing prefix \"Supreme Court is elected for a four @ - @ year term\"\n",
            "Probing prefix \"Court is elected for a four @ - @ year term\"\n",
            "Probing prefix \"is elected for a four @ - @ year term\"\n",
            "Probing prefix \"elected for a four @ - @ year term\"\n",
            "Probing prefix \"for a four @ - @ year term\"\n",
            "Probing prefix \"a four @ - @ year term\"\n",
            "Full token list for for prefix \"a four @ - @ year term\": [('.', 2), ('in', 1), ('by', 1)]\n",
            "Top-k tokens for prefix \"a four @ - @ year term\": [('.', 2), ('in', 1), ('by', 1)]\n",
            "Probing prefix \"The president of the Supreme Court is elected for a four @ - @ year term by\"\n",
            "Probing prefix \"president of the Supreme Court is elected for a four @ - @ year term by\"\n",
            "Probing prefix \"of the Supreme Court is elected for a four @ - @ year term by\"\n",
            "Probing prefix \"the Supreme Court is elected for a four @ - @ year term by\"\n",
            "Probing prefix \"Supreme Court is elected for a four @ - @ year term by\"\n",
            "Probing prefix \"Court is elected for a four @ - @ year term by\"\n",
            "Probing prefix \"is elected for a four @ - @ year term by\"\n",
            "Probing prefix \"elected for a four @ - @ year term by\"\n",
            "Probing prefix \"for a four @ - @ year term by\"\n",
            "Probing prefix \"a four @ - @ year term by\"\n",
            "Probing prefix \"four @ - @ year term by\"\n",
            "Full token list for for prefix \"four @ - @ year term by\": [('the', 1)]\n",
            "Top-k tokens for prefix \"four @ - @ year term by\": [('the', 1)]\n",
            "Probing prefix \"The president of the Supreme Court is elected for a four @ - @ year term by the\"\n",
            "Probing prefix \"president of the Supreme Court is elected for a four @ - @ year term by the\"\n",
            "Probing prefix \"of the Supreme Court is elected for a four @ - @ year term by the\"\n",
            "Probing prefix \"the Supreme Court is elected for a four @ - @ year term by the\"\n",
            "Probing prefix \"Supreme Court is elected for a four @ - @ year term by the\"\n",
            "Probing prefix \"Court is elected for a four @ - @ year term by the\"\n",
            "Probing prefix \"is elected for a four @ - @ year term by the\"\n",
            "Probing prefix \"elected for a four @ - @ year term by the\"\n",
            "Probing prefix \"for a four @ - @ year term by the\"\n",
            "Probing prefix \"a four @ - @ year term by the\"\n",
            "Probing prefix \"four @ - @ year term by the\"\n",
            "Probing prefix \"@ - @ year term by the\"\n",
            "Full token list for for prefix \"@ - @ year term by the\": [('Croatian', 1)]\n",
            "Top-k tokens for prefix \"@ - @ year term by the\": [('Croatian', 1)]\n",
            "Probing prefix \"The president of the Supreme Court is elected for a four @ - @ year term by the Croatian\"\n",
            "Probing prefix \"president of the Supreme Court is elected for a four @ - @ year term by the Croatian\"\n",
            "Probing prefix \"of the Supreme Court is elected for a four @ - @ year term by the Croatian\"\n",
            "Probing prefix \"the Supreme Court is elected for a four @ - @ year term by the Croatian\"\n",
            "Probing prefix \"Supreme Court is elected for a four @ - @ year term by the Croatian\"\n",
            "Probing prefix \"Court is elected for a four @ - @ year term by the Croatian\"\n",
            "Probing prefix \"is elected for a four @ - @ year term by the Croatian\"\n",
            "Probing prefix \"elected for a four @ - @ year term by the Croatian\"\n",
            "Probing prefix \"for a four @ - @ year term by the Croatian\"\n",
            "Probing prefix \"a four @ - @ year term by the Croatian\"\n",
            "Probing prefix \"four @ - @ year term by the Croatian\"\n",
            "Probing prefix \"@ - @ year term by the Croatian\"\n",
            "Probing prefix \"- @ year term by the Croatian\"\n",
            "Full token list for for prefix \"- @ year term by the Croatian\": [('Parliament', 1)]\n",
            "Top-k tokens for prefix \"- @ year term by the Croatian\": [('Parliament', 1)]\n",
            "Probing prefix \"The president of the Supreme Court is elected for a four @ - @ year term by the Croatian Parliament\"\n",
            "Probing prefix \"president of the Supreme Court is elected for a four @ - @ year term by the Croatian Parliament\"\n",
            "Probing prefix \"of the Supreme Court is elected for a four @ - @ year term by the Croatian Parliament\"\n",
            "Probing prefix \"the Supreme Court is elected for a four @ - @ year term by the Croatian Parliament\"\n",
            "Probing prefix \"Supreme Court is elected for a four @ - @ year term by the Croatian Parliament\"\n",
            "Probing prefix \"Court is elected for a four @ - @ year term by the Croatian Parliament\"\n",
            "Probing prefix \"is elected for a four @ - @ year term by the Croatian Parliament\"\n",
            "Probing prefix \"elected for a four @ - @ year term by the Croatian Parliament\"\n",
            "Probing prefix \"for a four @ - @ year term by the Croatian Parliament\"\n",
            "Probing prefix \"a four @ - @ year term by the Croatian Parliament\"\n",
            "Probing prefix \"four @ - @ year term by the Croatian Parliament\"\n",
            "Probing prefix \"@ - @ year term by the Croatian Parliament\"\n",
            "Probing prefix \"- @ year term by the Croatian Parliament\"\n",
            "Probing prefix \"@ year term by the Croatian Parliament\"\n",
            "Full token list for for prefix \"@ year term by the Croatian Parliament\": [('at', 1)]\n",
            "Top-k tokens for prefix \"@ year term by the Croatian Parliament\": [('at', 1)]\n",
            "Probing prefix \"The president of the Supreme Court is elected for a four @ - @ year term by the Croatian Parliament at\"\n",
            "Probing prefix \"president of the Supreme Court is elected for a four @ - @ year term by the Croatian Parliament at\"\n",
            "Probing prefix \"of the Supreme Court is elected for a four @ - @ year term by the Croatian Parliament at\"\n",
            "Probing prefix \"the Supreme Court is elected for a four @ - @ year term by the Croatian Parliament at\"\n",
            "Probing prefix \"Supreme Court is elected for a four @ - @ year term by the Croatian Parliament at\"\n",
            "Probing prefix \"Court is elected for a four @ - @ year term by the Croatian Parliament at\"\n",
            "Probing prefix \"is elected for a four @ - @ year term by the Croatian Parliament at\"\n",
            "Probing prefix \"elected for a four @ - @ year term by the Croatian Parliament at\"\n",
            "Probing prefix \"for a four @ - @ year term by the Croatian Parliament at\"\n",
            "Probing prefix \"a four @ - @ year term by the Croatian Parliament at\"\n",
            "Probing prefix \"four @ - @ year term by the Croatian Parliament at\"\n",
            "Probing prefix \"@ - @ year term by the Croatian Parliament at\"\n",
            "Probing prefix \"- @ year term by the Croatian Parliament at\"\n",
            "Probing prefix \"@ year term by the Croatian Parliament at\"\n",
            "Probing prefix \"year term by the Croatian Parliament at\"\n",
            "Full token list for for prefix \"year term by the Croatian Parliament at\": [('the', 1)]\n",
            "Top-k tokens for prefix \"year term by the Croatian Parliament at\": [('the', 1)]\n",
            "Probing prefix \"The president of the Supreme Court is elected for a four @ - @ year term by the Croatian Parliament at the\"\n",
            "Probing prefix \"president of the Supreme Court is elected for a four @ - @ year term by the Croatian Parliament at the\"\n",
            "Probing prefix \"of the Supreme Court is elected for a four @ - @ year term by the Croatian Parliament at the\"\n",
            "Probing prefix \"the Supreme Court is elected for a four @ - @ year term by the Croatian Parliament at the\"\n",
            "Probing prefix \"Supreme Court is elected for a four @ - @ year term by the Croatian Parliament at the\"\n",
            "Probing prefix \"Court is elected for a four @ - @ year term by the Croatian Parliament at the\"\n",
            "Probing prefix \"is elected for a four @ - @ year term by the Croatian Parliament at the\"\n",
            "Probing prefix \"elected for a four @ - @ year term by the Croatian Parliament at the\"\n",
            "Probing prefix \"for a four @ - @ year term by the Croatian Parliament at the\"\n",
            "Probing prefix \"a four @ - @ year term by the Croatian Parliament at the\"\n",
            "Probing prefix \"four @ - @ year term by the Croatian Parliament at the\"\n",
            "Probing prefix \"@ - @ year term by the Croatian Parliament at the\"\n",
            "Probing prefix \"- @ year term by the Croatian Parliament at the\"\n",
            "Probing prefix \"@ year term by the Croatian Parliament at the\"\n",
            "Probing prefix \"year term by the Croatian Parliament at the\"\n",
            "Probing prefix \"term by the Croatian Parliament at the\"\n",
            "Full token list for for prefix \"term by the Croatian Parliament at the\": [('proposal', 1)]\n",
            "Top-k tokens for prefix \"term by the Croatian Parliament at the\": [('proposal', 1)]\n",
            "Probing prefix \"The president of the Supreme Court is elected for a four @ - @ year term by the Croatian Parliament at the proposal\"\n",
            "Probing prefix \"president of the Supreme Court is elected for a four @ - @ year term by the Croatian Parliament at the proposal\"\n",
            "Probing prefix \"of the Supreme Court is elected for a four @ - @ year term by the Croatian Parliament at the proposal\"\n",
            "Probing prefix \"the Supreme Court is elected for a four @ - @ year term by the Croatian Parliament at the proposal\"\n",
            "Probing prefix \"Supreme Court is elected for a four @ - @ year term by the Croatian Parliament at the proposal\"\n",
            "Probing prefix \"Court is elected for a four @ - @ year term by the Croatian Parliament at the proposal\"\n",
            "Probing prefix \"is elected for a four @ - @ year term by the Croatian Parliament at the proposal\"\n",
            "Probing prefix \"elected for a four @ - @ year term by the Croatian Parliament at the proposal\"\n",
            "Probing prefix \"for a four @ - @ year term by the Croatian Parliament at the proposal\"\n",
            "Probing prefix \"a four @ - @ year term by the Croatian Parliament at the proposal\"\n",
            "Probing prefix \"four @ - @ year term by the Croatian Parliament at the proposal\"\n",
            "Probing prefix \"@ - @ year term by the Croatian Parliament at the proposal\"\n",
            "Probing prefix \"- @ year term by the Croatian Parliament at the proposal\"\n",
            "Probing prefix \"@ year term by the Croatian Parliament at the proposal\"\n",
            "Probing prefix \"year term by the Croatian Parliament at the proposal\"\n",
            "Probing prefix \"term by the Croatian Parliament at the proposal\"\n",
            "Probing prefix \"by the Croatian Parliament at the proposal\"\n",
            "Full token list for for prefix \"by the Croatian Parliament at the proposal\": [('of', 1)]\n",
            "Top-k tokens for prefix \"by the Croatian Parliament at the proposal\": [('of', 1)]\n",
            "Probing prefix \"The president of the Supreme Court is elected for a four @ - @ year term by the Croatian Parliament at the proposal of\"\n",
            "Probing prefix \"president of the Supreme Court is elected for a four @ - @ year term by the Croatian Parliament at the proposal of\"\n",
            "Probing prefix \"of the Supreme Court is elected for a four @ - @ year term by the Croatian Parliament at the proposal of\"\n",
            "Probing prefix \"the Supreme Court is elected for a four @ - @ year term by the Croatian Parliament at the proposal of\"\n",
            "Probing prefix \"Supreme Court is elected for a four @ - @ year term by the Croatian Parliament at the proposal of\"\n",
            "Probing prefix \"Court is elected for a four @ - @ year term by the Croatian Parliament at the proposal of\"\n",
            "Probing prefix \"is elected for a four @ - @ year term by the Croatian Parliament at the proposal of\"\n",
            "Probing prefix \"elected for a four @ - @ year term by the Croatian Parliament at the proposal of\"\n",
            "Probing prefix \"for a four @ - @ year term by the Croatian Parliament at the proposal of\"\n",
            "Probing prefix \"a four @ - @ year term by the Croatian Parliament at the proposal of\"\n",
            "Probing prefix \"four @ - @ year term by the Croatian Parliament at the proposal of\"\n",
            "Probing prefix \"@ - @ year term by the Croatian Parliament at the proposal of\"\n",
            "Probing prefix \"- @ year term by the Croatian Parliament at the proposal of\"\n",
            "Probing prefix \"@ year term by the Croatian Parliament at the proposal of\"\n",
            "Probing prefix \"year term by the Croatian Parliament at the proposal of\"\n",
            "Probing prefix \"term by the Croatian Parliament at the proposal of\"\n",
            "Probing prefix \"by the Croatian Parliament at the proposal of\"\n",
            "Probing prefix \"the Croatian Parliament at the proposal of\"\n",
            "Full token list for for prefix \"the Croatian Parliament at the proposal of\": [('the', 1)]\n",
            "Top-k tokens for prefix \"the Croatian Parliament at the proposal of\": [('the', 1)]\n",
            "Probing prefix \"The president of the Supreme Court is elected for a four @ - @ year term by the Croatian Parliament at the proposal of the\"\n",
            "Probing prefix \"president of the Supreme Court is elected for a four @ - @ year term by the Croatian Parliament at the proposal of the\"\n",
            "Probing prefix \"of the Supreme Court is elected for a four @ - @ year term by the Croatian Parliament at the proposal of the\"\n",
            "Probing prefix \"the Supreme Court is elected for a four @ - @ year term by the Croatian Parliament at the proposal of the\"\n",
            "Probing prefix \"Supreme Court is elected for a four @ - @ year term by the Croatian Parliament at the proposal of the\"\n",
            "Probing prefix \"Court is elected for a four @ - @ year term by the Croatian Parliament at the proposal of the\"\n",
            "Probing prefix \"is elected for a four @ - @ year term by the Croatian Parliament at the proposal of the\"\n",
            "Probing prefix \"elected for a four @ - @ year term by the Croatian Parliament at the proposal of the\"\n",
            "Probing prefix \"for a four @ - @ year term by the Croatian Parliament at the proposal of the\"\n",
            "Probing prefix \"a four @ - @ year term by the Croatian Parliament at the proposal of the\"\n",
            "Probing prefix \"four @ - @ year term by the Croatian Parliament at the proposal of the\"\n",
            "Probing prefix \"@ - @ year term by the Croatian Parliament at the proposal of the\"\n",
            "Probing prefix \"- @ year term by the Croatian Parliament at the proposal of the\"\n",
            "Probing prefix \"@ year term by the Croatian Parliament at the proposal of the\"\n",
            "Probing prefix \"year term by the Croatian Parliament at the proposal of the\"\n",
            "Probing prefix \"term by the Croatian Parliament at the proposal of the\"\n",
            "Probing prefix \"by the Croatian Parliament at the proposal of the\"\n",
            "Probing prefix \"the Croatian Parliament at the proposal of the\"\n",
            "Probing prefix \"Croatian Parliament at the proposal of the\"\n",
            "Full token list for for prefix \"Croatian Parliament at the proposal of the\": [('President', 1)]\n",
            "Top-k tokens for prefix \"Croatian Parliament at the proposal of the\": [('President', 1)]\n",
            "Probing prefix \"The president of the Supreme Court is elected for a four @ - @ year term by the Croatian Parliament at the proposal of the President\"\n",
            "Probing prefix \"president of the Supreme Court is elected for a four @ - @ year term by the Croatian Parliament at the proposal of the President\"\n",
            "Probing prefix \"of the Supreme Court is elected for a four @ - @ year term by the Croatian Parliament at the proposal of the President\"\n",
            "Probing prefix \"the Supreme Court is elected for a four @ - @ year term by the Croatian Parliament at the proposal of the President\"\n",
            "Probing prefix \"Supreme Court is elected for a four @ - @ year term by the Croatian Parliament at the proposal of the President\"\n",
            "Probing prefix \"Court is elected for a four @ - @ year term by the Croatian Parliament at the proposal of the President\"\n",
            "Probing prefix \"is elected for a four @ - @ year term by the Croatian Parliament at the proposal of the President\"\n",
            "Probing prefix \"elected for a four @ - @ year term by the Croatian Parliament at the proposal of the President\"\n",
            "Probing prefix \"for a four @ - @ year term by the Croatian Parliament at the proposal of the President\"\n",
            "Probing prefix \"a four @ - @ year term by the Croatian Parliament at the proposal of the President\"\n",
            "Probing prefix \"four @ - @ year term by the Croatian Parliament at the proposal of the President\"\n",
            "Probing prefix \"@ - @ year term by the Croatian Parliament at the proposal of the President\"\n",
            "Probing prefix \"- @ year term by the Croatian Parliament at the proposal of the President\"\n",
            "Probing prefix \"@ year term by the Croatian Parliament at the proposal of the President\"\n",
            "Probing prefix \"year term by the Croatian Parliament at the proposal of the President\"\n",
            "Probing prefix \"term by the Croatian Parliament at the proposal of the President\"\n",
            "Probing prefix \"by the Croatian Parliament at the proposal of the President\"\n",
            "Probing prefix \"the Croatian Parliament at the proposal of the President\"\n",
            "Probing prefix \"Croatian Parliament at the proposal of the President\"\n",
            "Probing prefix \"Parliament at the proposal of the President\"\n",
            "Full token list for for prefix \"Parliament at the proposal of the President\": [('of', 1)]\n",
            "Top-k tokens for prefix \"Parliament at the proposal of the President\": [('of', 1)]\n",
            "Probing prefix \"The president of the Supreme Court is elected for a four @ - @ year term by the Croatian Parliament at the proposal of the President of\"\n",
            "Probing prefix \"president of the Supreme Court is elected for a four @ - @ year term by the Croatian Parliament at the proposal of the President of\"\n",
            "Probing prefix \"of the Supreme Court is elected for a four @ - @ year term by the Croatian Parliament at the proposal of the President of\"\n",
            "Probing prefix \"the Supreme Court is elected for a four @ - @ year term by the Croatian Parliament at the proposal of the President of\"\n",
            "Probing prefix \"Supreme Court is elected for a four @ - @ year term by the Croatian Parliament at the proposal of the President of\"\n",
            "Probing prefix \"Court is elected for a four @ - @ year term by the Croatian Parliament at the proposal of the President of\"\n",
            "Probing prefix \"is elected for a four @ - @ year term by the Croatian Parliament at the proposal of the President of\"\n",
            "Probing prefix \"elected for a four @ - @ year term by the Croatian Parliament at the proposal of the President of\"\n",
            "Probing prefix \"for a four @ - @ year term by the Croatian Parliament at the proposal of the President of\"\n",
            "Probing prefix \"a four @ - @ year term by the Croatian Parliament at the proposal of the President of\"\n",
            "Probing prefix \"four @ - @ year term by the Croatian Parliament at the proposal of the President of\"\n",
            "Probing prefix \"@ - @ year term by the Croatian Parliament at the proposal of the President of\"\n",
            "Probing prefix \"- @ year term by the Croatian Parliament at the proposal of the President of\"\n",
            "Probing prefix \"@ year term by the Croatian Parliament at the proposal of the President of\"\n",
            "Probing prefix \"year term by the Croatian Parliament at the proposal of the President of\"\n",
            "Probing prefix \"term by the Croatian Parliament at the proposal of the President of\"\n",
            "Probing prefix \"by the Croatian Parliament at the proposal of the President of\"\n",
            "Probing prefix \"the Croatian Parliament at the proposal of the President of\"\n",
            "Probing prefix \"Croatian Parliament at the proposal of the President of\"\n",
            "Probing prefix \"Parliament at the proposal of the President of\"\n",
            "Probing prefix \"at the proposal of the President of\"\n",
            "Full token list for for prefix \"at the proposal of the President of\": [('the', 1)]\n",
            "Top-k tokens for prefix \"at the proposal of the President of\": [('the', 1)]\n",
            "Probing prefix \"The president of the Supreme Court is elected for a four @ - @ year term by the Croatian Parliament at the proposal of the President of the\"\n",
            "Probing prefix \"president of the Supreme Court is elected for a four @ - @ year term by the Croatian Parliament at the proposal of the President of the\"\n",
            "Probing prefix \"of the Supreme Court is elected for a four @ - @ year term by the Croatian Parliament at the proposal of the President of the\"\n",
            "Probing prefix \"the Supreme Court is elected for a four @ - @ year term by the Croatian Parliament at the proposal of the President of the\"\n",
            "Probing prefix \"Supreme Court is elected for a four @ - @ year term by the Croatian Parliament at the proposal of the President of the\"\n",
            "Probing prefix \"Court is elected for a four @ - @ year term by the Croatian Parliament at the proposal of the President of the\"\n",
            "Probing prefix \"is elected for a four @ - @ year term by the Croatian Parliament at the proposal of the President of the\"\n",
            "Probing prefix \"elected for a four @ - @ year term by the Croatian Parliament at the proposal of the President of the\"\n",
            "Probing prefix \"for a four @ - @ year term by the Croatian Parliament at the proposal of the President of the\"\n",
            "Probing prefix \"a four @ - @ year term by the Croatian Parliament at the proposal of the President of the\"\n",
            "Probing prefix \"four @ - @ year term by the Croatian Parliament at the proposal of the President of the\"\n",
            "Probing prefix \"@ - @ year term by the Croatian Parliament at the proposal of the President of the\"\n",
            "Probing prefix \"- @ year term by the Croatian Parliament at the proposal of the President of the\"\n",
            "Probing prefix \"@ year term by the Croatian Parliament at the proposal of the President of the\"\n",
            "Probing prefix \"year term by the Croatian Parliament at the proposal of the President of the\"\n",
            "Probing prefix \"term by the Croatian Parliament at the proposal of the President of the\"\n",
            "Probing prefix \"by the Croatian Parliament at the proposal of the President of the\"\n",
            "Probing prefix \"the Croatian Parliament at the proposal of the President of the\"\n",
            "Probing prefix \"Croatian Parliament at the proposal of the President of the\"\n",
            "Probing prefix \"Parliament at the proposal of the President of the\"\n",
            "Probing prefix \"at the proposal of the President of the\"\n",
            "Probing prefix \"the proposal of the President of the\"\n",
            "Full token list for for prefix \"the proposal of the President of the\": [('Republic', 1)]\n",
            "Top-k tokens for prefix \"the proposal of the President of the\": [('Republic', 1)]\n",
            "Probing prefix \"The president of the Supreme Court is elected for a four @ - @ year term by the Croatian Parliament at the proposal of the President of the Republic\"\n",
            "Probing prefix \"president of the Supreme Court is elected for a four @ - @ year term by the Croatian Parliament at the proposal of the President of the Republic\"\n",
            "Probing prefix \"of the Supreme Court is elected for a four @ - @ year term by the Croatian Parliament at the proposal of the President of the Republic\"\n",
            "Probing prefix \"the Supreme Court is elected for a four @ - @ year term by the Croatian Parliament at the proposal of the President of the Republic\"\n",
            "Probing prefix \"Supreme Court is elected for a four @ - @ year term by the Croatian Parliament at the proposal of the President of the Republic\"\n",
            "Probing prefix \"Court is elected for a four @ - @ year term by the Croatian Parliament at the proposal of the President of the Republic\"\n",
            "Probing prefix \"is elected for a four @ - @ year term by the Croatian Parliament at the proposal of the President of the Republic\"\n",
            "Probing prefix \"elected for a four @ - @ year term by the Croatian Parliament at the proposal of the President of the Republic\"\n",
            "Probing prefix \"for a four @ - @ year term by the Croatian Parliament at the proposal of the President of the Republic\"\n",
            "Probing prefix \"a four @ - @ year term by the Croatian Parliament at the proposal of the President of the Republic\"\n",
            "Probing prefix \"four @ - @ year term by the Croatian Parliament at the proposal of the President of the Republic\"\n",
            "Probing prefix \"@ - @ year term by the Croatian Parliament at the proposal of the President of the Republic\"\n",
            "Probing prefix \"- @ year term by the Croatian Parliament at the proposal of the President of the Republic\"\n",
            "Probing prefix \"@ year term by the Croatian Parliament at the proposal of the President of the Republic\"\n",
            "Probing prefix \"year term by the Croatian Parliament at the proposal of the President of the Republic\"\n",
            "Probing prefix \"term by the Croatian Parliament at the proposal of the President of the Republic\"\n",
            "Probing prefix \"by the Croatian Parliament at the proposal of the President of the Republic\"\n",
            "Probing prefix \"the Croatian Parliament at the proposal of the President of the Republic\"\n",
            "Probing prefix \"Croatian Parliament at the proposal of the President of the Republic\"\n",
            "Probing prefix \"Parliament at the proposal of the President of the Republic\"\n",
            "Probing prefix \"at the proposal of the President of the Republic\"\n",
            "Probing prefix \"the proposal of the President of the Republic\"\n",
            "Probing prefix \"proposal of the President of the Republic\"\n",
            "Full token list for for prefix \"proposal of the President of the Republic\": [('.', 1)]\n",
            "Top-k tokens for prefix \"proposal of the President of the Republic\": [('.', 1)]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The president of the Supreme Court is elected for a four @ - @ year term by the Croatian Parliament at the proposal of the President of the Republic .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the debug output, we can see that the model has memorized longer sequences, which it will faithfully reproduce, for lack of alternatives. Let's try a few more."
      ],
      "metadata": {
        "id": "rw1bbu2Xa1gZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "complete_lm(model, \"Cassini\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "G8_MF4dYvcnh",
        "outputId": "215e82ec-c0b0-45e7-e973-5aa3616b8106"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Cassini probe , en route to Saturn , flew by Jupiter and provided some of the highest @ - @ resolution images ever taken of the planet .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "complete_lm(model, \"Schwarzenegger\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "pAsehkV3vnkK",
        "outputId": "efd45223-799c-4389-a6d6-79464c43c324"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Schwarzenegger character Terminator , he prompts Leslie to do that impression as well .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "complete_lm(model, \"And then the\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "XTFtX49jvszX",
        "outputId": "118aaf29-3d11-49cd-b742-87b1b8eeeecd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'And then the Allied invasion of Italy .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "complete_lm(model, \"Aliens have\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "1oEhAfl_v4zK",
        "outputId": "f267c365-82ff-4590-a6ff-c1d96b7a5fc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Aliens have the Simpsons visit another country , that country gets furious , including Australia `` .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us contrast this with a large language model."
      ],
      "metadata": {
        "id": "Mytw9IjEvc6y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Playing with pre-trained large language models\n",
        "Even our small n-gram language model takes up considerable amount of RAM and a surprising amount of training time.\n",
        "\n",
        "More capable large language models take many orders of magnitude more training time (days to months), as they are trained on trillions of tokens instead of just a few hundred thousand tokens. Their architecture is much more complex, with the number of model parameters ranging from a few hundred millions (BERT) to a trillion (like Google Brain's [latest entry](https://aibusiness.com/nlp/google-brain-unveils-trillion-parameter-ai-language-model-the-largest-yet)). They are also not just learning simple n-gram statistics, but complex latent variables, that take into account linguistic and semantic properties of text at a much, much deeper level.\n",
        "\n",
        "As such, the community around large language models has started the trend of publishing **pre-trained large language models**, which allows organizations and individuals without the necessary resources to use and adapt these models.\n",
        "\n",
        "A popular hub for exchanging models is [Hugging Face](https://huggingface.co/models), where pre-trained, **open-weights models** like Llama, Mistral, and others can be found. The models are published togehter with the model architecture, which allows them to be run via [Hugging Face transformers](https://huggingface.co/docs/transformers/en/index) and similar libraries and frameworks.\n",
        "\n",
        "We will dive into the details for large language model architecture later. For now, we want to load a \"small\" large language model and compare its output with our own language model above. Ultimately, large language models and our punny n-gram do the same thing: predict the next token for a sequence.\n",
        "\n",
        "## GPU support\n",
        "Running such large language models on the CPU is possible, but not the most enjoybale past time in terms of speed. For any productive work, GPU support is mandatory.\n",
        "\n",
        "To run a large language model on the GPU in Google Colab, we need to select a runtime with GPU support, like T4 (free), A100 (paid), or V100 (paid). Click on `Runtime -> Change Runtime` above, switch to a GPU runtime, and restart the session."
      ],
      "metadata": {
        "id": "2Y5SYNmDbCha"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quantization\n",
        "The free Google Colab T4 runtime features a GPU with 16GB of RAM. How much RAM a model requires can be ballparked via its parameter count.\n",
        "\n",
        "The number of parameters is usually part of the model name, e.g. the Mistral-7B model has 7 billion parameters. How big is one parameter? All of these models are made up of deep neural networks. Like the one we built in the supervised learning section. One parameter is a weight (or bias) in those deep neural networks. Weights and biases are encoded as floating point numbers. Floating point numbers can have a bit depth ranging from [4-bit](https://arxiv.org/abs/2310.16836) to 64-bit. Most open-weight models are published with [16-bit wide float](https://en.wikipedia.org/wiki/Half-precision_floating-point_format) or [bfloat](https://en.wikipedia.org/wiki/Bfloat16_floating-point_format) weights and biases.\n",
        "\n",
        "A 7B model with weights encoded as 16-bit (b)float thus requires at a minimum 14GB of RAM. This does not include working memory required to hold auxiliary data.\n",
        "\n",
        "Getting a model to fit into a consumer grade GPU, or a Google Colab T4 instance is hard to impossible.\n",
        "\n",
        "Thus, pracitioners have come up with quantization schemes that reduce the bit-depth of model weights to 8- or even 4-bits. This reduces memory requirements by 2x-3x, and can also speeds up inference. Of course, there are also downsides: since the weights are compressed lossily, the model may suffer some quality degradation. For many models, this degradation is often acceptable though, especially during development.\n",
        "\n",
        "Once such quantization method is called [AutoAWQ](https://github.com/casper-hansen/AutoAWQ). It quantized model weights to 4-bit, while trying to maintain as much fidelity as possible. AutoAWQ is compatible with the Huggin Face Transformers library, which we'll use to load and use AWQ quantized LLMs.\n",
        "\n",
        "Let's install AutoAWQ:\n"
      ],
      "metadata": {
        "id": "Cdd4Q56Bf5Ho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install autoawq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0yRwCaPKkY4",
        "outputId": "dc852275-716a-45ba-da41-ebcecf954f08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting autoawq\n",
            "  Downloading autoawq-0.2.2-cp310-cp310-manylinux2014_x86_64.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.8/76.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from autoawq) (2.1.0+cu121)\n",
            "Requirement already satisfied: transformers>=4.35.0 in /usr/local/lib/python3.10/dist-packages (from autoawq) (4.37.2)\n",
            "Requirement already satisfied: tokenizers>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from autoawq) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from autoawq) (4.9.0)\n",
            "Requirement already satisfied: triton in /usr/local/lib/python3.10/dist-packages (from autoawq) (2.1.0)\n",
            "Collecting accelerate (from autoawq)\n",
            "  Downloading accelerate-0.27.2-py3-none-any.whl (279 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.0/280.0 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets (from autoawq)\n",
            "  Downloading datasets-2.17.1-py3-none-any.whl (536 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.7/536.7 kB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting zstandard (from autoawq)\n",
            "  Downloading zstandard-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autoawq-kernels (from autoawq)\n",
            "  Downloading autoawq_kernels-0.0.5-cp310-cp310-manylinux2014_x86_64.whl (29.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.7/29.7 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.12.1->autoawq) (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->autoawq) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->autoawq) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->autoawq) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->autoawq) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.1->autoawq) (2023.6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.35.0->autoawq) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.35.0->autoawq) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.35.0->autoawq) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.35.0->autoawq) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.35.0->autoawq) (2.31.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.35.0->autoawq) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.35.0->autoawq) (4.66.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->autoawq) (5.9.5)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->autoawq) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->autoawq) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets->autoawq)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->autoawq) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->autoawq) (3.4.1)\n",
            "Collecting multiprocess (from datasets->autoawq)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->autoawq) (3.9.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->autoawq) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->autoawq) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->autoawq) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->autoawq) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->autoawq) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->autoawq) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.35.0->autoawq) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.35.0->autoawq) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.35.0->autoawq) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.35.0->autoawq) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.1->autoawq) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->autoawq) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->autoawq) (2023.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.0.1->autoawq) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets->autoawq) (1.16.0)\n",
            "Installing collected packages: zstandard, dill, multiprocess, autoawq-kernels, accelerate, datasets, autoawq\n",
            "Successfully installed accelerate-0.27.2 autoawq-0.2.2 autoawq-kernels-0.0.5 datasets-2.17.1 dill-0.3.8 multiprocess-0.70.16 zstandard-0.22.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Mistral-7B\n",
        "A handful of notorious users on Hugging Face seem to have it made their lifegoal to quantize any and all open-weight LLM models in existance. The most prominent is \"TheBloke\", who also provides an AWQ quantized version of the [Mistral-7B model](https://huggingface.co/TheBloke/Mistral-7B-v0.1-AWQ).\n",
        "\n",
        "Mistral is a family of LLMs by [Mistral AI](https://mistral.ai/contact/), a french company working in the AI space. Mistral models are regularly at the top of [LLM model benchmarks](https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard).\n",
        "\n",
        "Like most LLM families, Mistral comes in [several flavours](https://huggingface.co/mistralai). Generally, we differentiate between pre-trained models with and without **instruction fine-tuning**. Models without instruction fine-tuning are sort of \"raw\". They can generally not follow instructions given to them, but will merely try to come up with the most likely next token, given a sequence. Just like our n-gram model above. Just way smarter.\n",
        "\n",
        "Let's load the AWQ quantized Mistral-7B from Hugging Face. To do so, we use the Hugging Face Transformers class `AutoModelForCausalLLM`. The class name already tells us, what the class does.\n",
        "\n",
        "`AutoModel` means, that the class knows how to load a specific model's architecture and its corresponding parameters.\n",
        "\n",
        "The `ForCausalLLM` part means that the model to be loaded is expected to be a large language model for next word prediction (also known as causal language modeling). Check out the [Auto Classes](https://huggingface.co/docs/transformers/model_doc/auto) documentation for more details.\n",
        "\n",
        "The `AutoModelForCausalLM` class has a static method `from_pretrained()` which takes the identifier of a causal large language model to be downloaded from the Hugging Face Hub. The identifier is composed of the name of the user or organization that has uploaded the model to the hub, e.g. \"TheBloke\", and the model name, e.g. \"Mistral-7B-v0.1-AWQ\", separated by a slash. You can also specify a local directory instead.\n",
        "\n",
        "The method will cache the model locally, so subsequent loads are faster. Once downloaded, the `from_pretrained` method then instantiates the concrete model class, in our case [MistralForCausalLM](https://huggingface.co/docs/transformers/v4.38.1/en/model_doc/mistral#transformers.MistralForCausalLM). This class knows how to instantiate all the modules and layers of the model. Once instantiated, the model parameters from the downloaded (or local) model file(s) are loaded into the model.\n",
        "\n",
        "The model can be instantiated CPU-side, or GPU-side. We can let the `from_pretrained` method pick the best option by passing `device_map=\"cuda\"` as a parameter. [CUDA](https://developer.nvidia.com/cuda-zone) by NVIDIA is the defacto framework when it comes to doing computations on a GPU. It also only works for NVIDIA GPUs. Setting the parameter to \"cuda\" will make the method try to put the model on a CUDA enabled GPU if available.\n",
        "\n",
        "A lot of words for 3 lines of code. Here's how we load the model:\n"
      ],
      "metadata": {
        "id": "9t5t8QC7l_rC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM\n",
        "\n",
        "model_name = \"TheBloke/Mistral-7B-v0.1-AWQ\"\n",
        "llm = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"cuda\")"
      ],
      "metadata": {
        "id": "zzCQdsVO5Elb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Printing the model will tell us about its internal architecture. Constrast and compare this to our own little deepish neural network."
      ],
      "metadata": {
        "id": "LzxTOuAxsvGf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(llm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3KdblJcBuGk",
        "outputId": "0337cd41-7744-40e1-bbab-df240a8fbcd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MistralForCausalLM(\n",
            "  (model): MistralModel(\n",
            "    (embed_tokens): Embedding(32000, 4096, padding_idx=0)\n",
            "    (layers): ModuleList(\n",
            "      (0-31): 32 x MistralDecoderLayer(\n",
            "        (self_attn): MistralAttention(\n",
            "          (q_proj): WQLinear_GEMM(in_features=4096, out_features=4096, bias=False, w_bit=4, group_size=128)\n",
            "          (k_proj): WQLinear_GEMM(in_features=4096, out_features=1024, bias=False, w_bit=4, group_size=128)\n",
            "          (v_proj): WQLinear_GEMM(in_features=4096, out_features=1024, bias=False, w_bit=4, group_size=128)\n",
            "          (o_proj): WQLinear_GEMM(in_features=4096, out_features=4096, bias=False, w_bit=4, group_size=128)\n",
            "          (rotary_emb): MistralRotaryEmbedding()\n",
            "        )\n",
            "        (mlp): MistralMLP(\n",
            "          (gate_proj): WQLinear_GEMM(in_features=4096, out_features=14336, bias=False, w_bit=4, group_size=128)\n",
            "          (up_proj): WQLinear_GEMM(in_features=4096, out_features=14336, bias=False, w_bit=4, group_size=128)\n",
            "          (down_proj): WQLinear_GEMM(in_features=14336, out_features=4096, bias=False, w_bit=4, group_size=128)\n",
            "          (act_fn): SiLU()\n",
            "        )\n",
            "        (input_layernorm): MistralRMSNorm()\n",
            "        (post_attention_layernorm): MistralRMSNorm()\n",
            "      )\n",
            "    )\n",
            "    (norm): MistralRMSNorm()\n",
            "  )\n",
            "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization\n",
        "While large language models deal with text, they can not directly work with direct text input. Just as in case of our n-gram model, we need to use a tokenizer to preprocess any text we want to pass to the large language model.\n",
        "\n",
        "Tokenizers for large language model are a science in their own right. We've already mentioned [binary pair encoding](https://en.wikipedia.org/wiki/Byte_pair_encoding) and many other tokenizers, which does not operate on word boundaries, like in our n-gram case.\n",
        "\n",
        "Whatever model we use, we must ensure to use the same tokenizer that was used for pre-training it. Thankfully, the information which tokenizer is needed for a model is part of the model configuration. Which means, we can automatically load it, just like we did with with the model itself. The Hugging Face Transformers library has another auto class for that, `AutoTokenizer`. Here is how we load the tokenizer for the mistral model:"
      ],
      "metadata": {
        "id": "IR5fUjXCs5lD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "9C0B71F1yN4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenizing a text string is equally simple:"
      ],
      "metadata": {
        "id": "J0IoPdAqyaZb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = tokenizer(\"Peach is in a different castle\")\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJUnh6Icyg4E",
        "outputId": "e37149bd-ef78-4b40-f2fc-804011a19e84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [1, 3242, 595, 349, 297, 264, 1581, 19007], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The tokenizer returns a set of ids. The first id with value `1` signals the start of the sequence. The remaining ids map to one token from the vocabulary the tokenizer has. This tokenizer has a total of 32000 tokens in its vocabulary. When a string is tokenized, it gets broken down into ids from that vocabulary.\n",
        "\n",
        "We can decode the ids back to text:"
      ],
      "metadata": {
        "id": "aIW1JaWzyoTz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(tokens[\"input_ids\"])):\n",
        "  print(tokenizer.decode(tokens[\"input_ids\"][i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4jy3zmQy6bp",
        "outputId": "4b3029ed-233a-4d52-eeae-22976e0f39eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s>\n",
            "Pe\n",
            "ach\n",
            "is\n",
            "in\n",
            "a\n",
            "different\n",
            "castle\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Where `<s>` is the textual encoding for the special \"beginning of stream\" token.\n",
        "\n",
        "The `attention_mask` is used to tell the model which of the tokens it can ignore (`0`) and which tokens it should consider (`1`). For our purpose, we'll always have an attention mask full of `1`s when passing input to the LLM.\n",
        "\n",
        "The values returned by the `tokenizer` call above live CPU-side. However, our model lives GPU-side. We need to invoke the tokenizer with additional parameters, so it puts the tokens and attention mask in GPU RAM. Let's wrap this in a function:"
      ],
      "metadata": {
        "id": "1vt19NEJzQBV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_llm(input, max_length=4096):\n",
        "  inputs = tokenizer(input, return_tensors=\"pt\", max_length=1024, truncation=True);\n",
        "  inputs = {key: value.to(\"cuda\") for key, value in inputs.items()}\n",
        "  return inputs\n",
        "\n",
        "tokenize_llm(\"Peach is in a different castle\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiBOJ-jCz6Np",
        "outputId": "c631afab-00de-4455-fcc0-61daf051ecd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[    1,  3242,   595,   349,   297,   264,  1581, 19007]],\n",
              "        device='cuda:0'),\n",
              " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The input ids and attention mask have been converted to PyTorch tensors, which live on the GPU. We are ready to pass input to the LLM for it to predict the next word in a sequence."
      ],
      "metadata": {
        "id": "7EMuBjQi0zS0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logits and predicting the next word\n",
        "Let's start by tokenizing an input we also used with our n-gram model:"
      ],
      "metadata": {
        "id": "MI0KelXC0Nng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input = tokenize_llm(\"Cassini\")\n",
        "input"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUwG90x81Iup",
        "outputId": "6d77806a-6bd5-4fd4-bc91-bcbc61a164a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[    1, 13367,  3494]], device='cuda:0'),\n",
              " 'attention_mask': tensor([[1, 1, 1]], device='cuda:0')}"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `MistralModelForCausalLM` instance is actually a PyTorch `Module`, like our deep-ish neural network from the previous section. As such, we can make it predict output via:"
      ],
      "metadata": {
        "id": "WRlMAFL21Sir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm.eval()\n",
        "output = llm(**input)\n",
        "print(type(output))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdumclmZ1SF3",
        "outputId": "1ca25ab0-ea4c-49c0-b0a7-2ce56a6d9925"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'transformers.modeling_outputs.CausalLMOutputWithPast'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function returns an instance of [CausalLMOutputWithPast](https://huggingface.co/docs/transformers/v4.38.1/en/main_classes/output#transformers.modeling_outputs.CausalLMOutputWithPast). We are only interested in the `logits`, so lets have a look at what they are."
      ],
      "metadata": {
        "id": "76vqaGTa3RGe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output.logits.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CeRw830w3fiX",
        "outputId": "f329aec0-674c-4bed-d299-194456dd9f44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 32000])"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's a PyTorch tensor, with a very weird shape. Let's break it down.\n",
        "\n",
        "The first dimension of size `1` is the batch size, which is equivalent to the number of inputs we submitted. We only submitted a single input, so its size is 1.\n",
        "\n",
        "The next dimension (`3`) is the sequence length. We passed in the tokens for `Cassini`, which got tokenized to `3` tokens (including the beginning of stream token with id `1`).\n",
        "\n",
        "The final dimension has size `32000`. That is equivalent to the number of tokens in the vocabulary of the tokenizer.\n",
        "\n",
        "We thus get one vector with 32000 dimensions for each input token. Each element in this vector corresponds to one token in the vocabulary the tokenizer understands. The index of the element is equal to the id of the corresponding token in the vocabulary. And the value of a vector element gives us the (unnormalized) log-probability that this token is the next token in the sequence after the current token! This (unnormalized) log-probability for a token is also called the **logit score**.\n",
        "\n",
        "This is very similar to the token list we fetch for a prefix in our n-gram model. Except, we do it for the longest prefix match, instead of for every token position in the input.\n",
        "\n",
        "We can visualize the top 5 predicted tokens for each position in the input sequence."
      ],
      "metadata": {
        "id": "hnyOKC4P3glL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "data = []\n",
        "for i in range(output.logits.shape[1]):\n",
        "    logits_for_position = output.logits[0, i, :]\n",
        "    topk_values, topk_indices = torch.topk(logits_for_position, 5)\n",
        "    topk_tokens_with_scores = [(tokenizer.decode([idx.item()], skip_special_tokens=True), score.item()) for idx, score in zip(topk_indices, topk_values)]\n",
        "    for rank, (token, score) in enumerate(topk_tokens_with_scores, start=1):\n",
        "        data.append({\n",
        "            \"Position\": i,\n",
        "            \"Input Token\": tokenizer.decode(input[\"input_ids\"][0][i]),\n",
        "            \"Predicted Next Token\": token,\n",
        "            \"Logit Score\": score\n",
        "        })\n",
        "pd.DataFrame(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "B-9eXNoA6QMZ",
        "outputId": "4a58b0ab-1cd6-443e-930c-a21f15b45413"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Position Input Token Predicted Next Token  Logit Score\n",
              "0          0         <s>                    #    12.250000\n",
              "1          0         <s>                   ##    11.101562\n",
              "2          0         <s>                  ###    10.703125\n",
              "3          0         <s>                  The    10.062500\n",
              "4          0         <s>                 User    10.039062\n",
              "5          1        Cass                   ie    11.312500\n",
              "6          1        Cass                andra    11.164062\n",
              "7          1        Cass                  ini    10.843750\n",
              "8          1        Cass                  idy    10.445312\n",
              "9          1        Cass                  per    10.351562\n",
              "10         2         ini                 Sign    11.593750\n",
              "11         2         ini                   is    10.632812\n",
              "12         2         ini                    ’    10.000000\n",
              "13         2         ini                    '     9.671875\n",
              "14         2         ini                    -     9.460938"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1281934a-19e8-4c70-acb6-7302cb628697\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Position</th>\n",
              "      <th>Input Token</th>\n",
              "      <th>Predicted Next Token</th>\n",
              "      <th>Logit Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>&lt;s&gt;</td>\n",
              "      <td>#</td>\n",
              "      <td>12.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>&lt;s&gt;</td>\n",
              "      <td>##</td>\n",
              "      <td>11.101562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>&lt;s&gt;</td>\n",
              "      <td>###</td>\n",
              "      <td>10.703125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>&lt;s&gt;</td>\n",
              "      <td>The</td>\n",
              "      <td>10.062500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>&lt;s&gt;</td>\n",
              "      <td>User</td>\n",
              "      <td>10.039062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>Cass</td>\n",
              "      <td>ie</td>\n",
              "      <td>11.312500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>Cass</td>\n",
              "      <td>andra</td>\n",
              "      <td>11.164062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>Cass</td>\n",
              "      <td>ini</td>\n",
              "      <td>10.843750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>Cass</td>\n",
              "      <td>idy</td>\n",
              "      <td>10.445312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>Cass</td>\n",
              "      <td>per</td>\n",
              "      <td>10.351562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2</td>\n",
              "      <td>ini</td>\n",
              "      <td>Sign</td>\n",
              "      <td>11.593750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>2</td>\n",
              "      <td>ini</td>\n",
              "      <td>is</td>\n",
              "      <td>10.632812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>2</td>\n",
              "      <td>ini</td>\n",
              "      <td>’</td>\n",
              "      <td>10.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>2</td>\n",
              "      <td>ini</td>\n",
              "      <td>'</td>\n",
              "      <td>9.671875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>2</td>\n",
              "      <td>ini</td>\n",
              "      <td>-</td>\n",
              "      <td>9.460938</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1281934a-19e8-4c70-acb6-7302cb628697')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1281934a-19e8-4c70-acb6-7302cb628697 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1281934a-19e8-4c70-acb6-7302cb628697');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-aba4b754-0641-4755-b79b-a0c84fa008d2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-aba4b754-0641-4755-b79b-a0c84fa008d2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-aba4b754-0641-4755-b79b-a0c84fa008d2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"Position\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Input Token\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"<s>\",\n          \"Cass\",\n          \"ini\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Predicted Next Token\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 15,\n        \"samples\": [\n          \"per\",\n          \"is\",\n          \"#\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Logit Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7578136505882282,\n        \"min\": 9.4609375,\n        \"max\": 12.25,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          10.3515625,\n          10.6328125,\n          12.25\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A few interesting observations:\n",
        "\n",
        "* For the beginning of stream token `<s>`, that is for an empty input sequence, the model really wants to output \"#\", \"##\", \"###\". These are clearly markdown headings, which were likely very abundant in the training data.\n",
        "* For the next token `Cass`, the model thinks common names like `Cassie` or `Cassandra` would be appropriate.\n",
        "* For the last token in our input sequence, `ini`, the model predicts `Sign` as the most likely next token, followed by `is`\n",
        "\n",
        "For our final trick, we'll write a `complete_llm` function, that completes an input sequence up to a maximum number of generated tokens. We'll use the model's `generate` method for that, to make our life a little easier."
      ],
      "metadata": {
        "id": "-UJ8hDi2606o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def complete_llm(llm, input, max_length = 40):\n",
        "    input = tokenize_llm(input)\n",
        "    output_ids = llm.generate(**input, max_length=max_length, num_return_sequences=1)\n",
        "    generated_text = tokenizer.batch_decode(output_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
        "\n",
        "    return generated_text"
      ],
      "metadata": {
        "id": "gGUl-BjzAEh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "complete_llm(llm, \"The Cassini probe\")"
      ],
      "metadata": {
        "id": "hnxEYi0iAoPh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "2ab92888-7437-4970-fc47-3259dbd13434"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The Cassini probe has been orbiting Saturn for over a decade, and has been sending back some amazing images of the planet and its moons. But the probe is running out of fuel, and NASA has decided to end the mission by sending it into the atmosphere of Saturn.\\n\\nThe Cassini probe has been orbiting Saturn for over a decade, and has been sending back some amazing images of the planet and its moons. But the probe is running out of fuel, and NASA has decided to end the mission by sending it into the atmosphere of Saturn.\\n\\nThe Cassini probe has been orbiting Saturn for over a decade, and has been sending back some amazing images of the planet and its moons. But the probe is running out of fuel, and NASA has decided to end the mission by sending it into the atmosphere of Saturn.\\n\\nThe Cassini probe has been orbiting Saturn for over a decade, and has been sending back some amazing images of the planet and its moons. But the probe is running out of fuel, and NASA has decided to end the mission by sending it into the atmosphere of Saturn.\\n\\nThe Cassini probe has been orbiting Sat'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "complete_llm(llm, \"And then the\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "m_faKJan89qr",
        "outputId": "b9d54db6-a004-4e26-9175-8df7e515d34b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'And then the world changed.\\n\\nI’m not talking about the pandemic. I’m talking about the murder of George Floyd.\\n\\nI’m not talking about the protests'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "complete_llm(llm, \"Aliens have\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "E4g5nAu585S-",
        "outputId": "f5b6bed2-a0d3-4101-ecb0-903e7f922991"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Aliens have been a part of the Star Wars universe since the very beginning. In fact, the first Star Wars movie was originally titled Star Wars: Episode IV – The Star Wars.\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also check logits on OpenAI's playground.\n",
        "\n",
        "https://platform.openai.com/playground/p/hl8pCZ1Jj9wfD3P1l46uDEQj?mode=complete\n",
        "\n",
        "Hit \"Submit\", then click a token to view logits"
      ],
      "metadata": {
        "id": "GRdoZysIN2b5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running LLMs locally\n",
        "If you have a PC with a recent NVIDIA GPU and enough VRAM (Minimum 8GB) or a MacBook with an M1 or above (Minimum 16GB), you can try to run these models on your machine as well.\n",
        "\n",
        "There are different ways to run the models. All of them fetch the models from Hugging Face.\n",
        "\n",
        "* [LM Studio](https://lmstudio.ai/) a comprehensive GUI application that makes downloading and chatting with open-weight LLMs simple. Also supports serving models via an OpenAI compatible REST API.\n",
        "* [Ollama](https://ollama.com/), more or less a command line tool to quickly pull models from Hugging Face and run them locally. Also allows serving those files via a REST API that is compatible with the OpenAI API.\n",
        "* [llama.cpp](https://github.com/ggerganov/llama.cpp), a C++ library to load and run many open-weight models. Comes with its own file format (GGUF), and includes CLI tools for all kinds of tasks. Models can also be served via an OpenAI compatible REST API through [llama-cpp-python](https://llama-cpp-python.readthedocs.io/en/latest/server/).\n",
        "\n",
        "llama.cpp is the underpinning of many local open-weight model runners, including LM Studio and Ollama. It recently got support for [**LoRA fine-tuning**](https://rentry.org/cpu-lora) though only on the CPU, which is ... not great."
      ],
      "metadata": {
        "id": "cRgDEWNR-yHw"
      }
    }
  ]
}